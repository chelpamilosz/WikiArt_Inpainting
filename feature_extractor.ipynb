{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHN42RghFw82"
      },
      "outputs": [],
      "source": [
        "#!pip install torch torchvision torchaudio\n",
        "#!pip install einops\n",
        "#!pip install datasets\n",
        "#!pip install transformers\n",
        "#!pip install tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Biblioteki"
      ],
      "metadata": {
        "id": "dP0ALyfg5Hl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "import h5py\n",
        "from einops import rearrange\n",
        "from tqdm import tqdm\n",
        "\n",
        "import time"
      ],
      "metadata": {
        "id": "jRmeMcVs5FDj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wybór środowiska wykonawczego"
      ],
      "metadata": {
        "id": "xK4-d6uY5QQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Wybór urządzenia GPU (CUDA), jeśli dostępne\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Używane urządzenie:\", device)"
      ],
      "metadata": {
        "id": "MTKWtwto5P83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b4c9ec4-2a2e-48ee-98c2-f6a1116d583b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Używane urządzenie: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podłączenie Google Drive"
      ],
      "metadata": {
        "id": "0CwvyBRL5Y0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Podłączenie Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qGw5T8Pw5YlD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c453b4c-d36f-448f-b981-a17029637866"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ustawienie parametrów eksperymentu"
      ],
      "metadata": {
        "id": "Ti7vNC6D170W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ścieżka do zbioru danych\n",
        "file_path = '/content/drive/MyDrive/damaged_images.h5'\n",
        "\n",
        "#Ilość próbek do pobrania\n",
        "n_samples = 1000\n",
        "\n",
        "#Wielkość segmentu danych (ilość próbek do pobrania na raz w celu oszczędzenia pamięci, np. 1.000 z 10.000)\n",
        "#chunk_size = 1000\n",
        "'''To rozwiązanie się nie sprawdziło, kolidowało z ładowaniem batchy'''\n",
        "\n",
        "#Wielkość mini-batchy (ilość próbek jednoczesnie przetwarzanych przez model)\n",
        "batch_size = 32\n",
        "\n",
        "#Ilość procesów roboczych (colab ma limit 2)\n",
        "n_workers = 0\n",
        "\n",
        "#Liczba epok\n",
        "n_epochs = 2\n",
        "\n",
        "#Mieszanie kolejności próbek\n",
        "shuffle = True\n",
        "\n",
        "#Przekształcanie próbek - transformacja\n",
        "transform = transforms.Compose([\n",
        "    #transforms.ToPILImage(),\n",
        "    #transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "'''ToPILImage prawdopodobnie nie będzie potrzebny, Resize wyłączone dla szybszego przetwarzania,\n",
        "   ToTensor musi być bo chyba model nie ogarnia, że to tensory, albo ja coś źle zrozumiałem\n",
        "'''\n",
        "\n",
        "#Funkcja kosztu (przykładowo MSE)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "#Pretrenowany model\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "#Ilość warstw do Fine-tuningu (dostrajania)\n",
        "fine_tune_layers = 10"
      ],
      "metadata": {
        "id": "fRasXqST1XWm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Klasa ekstraktora cech"
      ],
      "metadata": {
        "id": "rindoFqS6DI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Zamrożenie wszystkich warstw modelu pretrenowanego - zablokowanie możliwości trenowania wag\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "#Odmrożenie n-warstw do Fine-tuningu (dostrajania)\n",
        "layer_count = 0\n",
        "for child in model.children():\n",
        "    layer_count += 1\n",
        "    if layer_count > len(list(model.children())) - fine_tune_layers:\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, original_model):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        #Odcięcie ostatniej warsatwy (klasyfikującej)\n",
        "        self.features = nn.Sequential(*list(original_model.children())[:-1])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "BOPkRg5r6C7_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Klasa zbioru danych - nieudana"
      ],
      "metadata": {
        "id": "EuafkKgn5zDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Poniżej jedna z wielu prób rozwiązania problemu ilości danych i braku pamięci\n",
        "#Pomysł był taki by pobierać dane co jakiś czas (np. po 1.000 próbek) aż do pewnego górnego limitu (np. 10.000)\n",
        "#Dataloader miał ładować te dane do przetwarzania z okreslonym batch_size\n",
        "\n",
        "'''\n",
        "class HDF5Dataset(Dataset):\n",
        "    def __init__(self, file_path, transform=None, chunk_size=1000, n_samples=None):\n",
        "        self.file_path = file_path\n",
        "        self.transform = transform\n",
        "        self.chunk_size = chunk_size\n",
        "        self.n_samples = n_samples\n",
        "\n",
        "        # Ustalamy całkowitą liczbę próbek\n",
        "        with h5py.File(self.file_path, 'r') as h5_file:\n",
        "            self.total_samples = min(len(h5_file['image']), self.n_samples) if self.n_samples else len(h5_file['image'])\n",
        "\n",
        "        self.current_chunk = None  # Zmienna przechowująca bieżący segment\n",
        "        self.num_chunks = (self.total_samples + self.chunk_size - 1) // self.chunk_size  # Liczba segmentów\n",
        "        self.chunk_idx = 0  # Indeks bieżącego segmentu\n",
        "\n",
        "        # Ładujemy pierwszy segment danych\n",
        "        self._load_chunk(0)\n",
        "\n",
        "    def _load_chunk(self, chunk_idx):\n",
        "        \"\"\"Ładuje segment danych bazując na indeksie segmentu.\"\"\"\n",
        "        #start_time = time.time()\n",
        "\n",
        "        start_idx = chunk_idx * self.chunk_size\n",
        "        end_idx = min(start_idx + self.chunk_size, self.total_samples)\n",
        "\n",
        "        with h5py.File(self.file_path, 'r') as h5_file:\n",
        "            self.current_chunk = h5_file['image'][start_idx:end_idx]\n",
        "\n",
        "        self.current_chunk_start = start_idx\n",
        "        #load_time = time.time() - start_time\n",
        "        #print(f\"Loaded chunk {chunk_idx + 1}/{self.num_chunks} from {start_idx} to {end_idx} in {load_time:.4f} seconds\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.current_chunk)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Pobieranie obrazu z aktualnie załadowanego segmentu\n",
        "        image = self.current_chunk[idx]\n",
        "\n",
        "        # Ewentualne przekształcenie wymiarów\n",
        "        if image.shape[0] == 3:\n",
        "            image = rearrange(image, 'c h w -> h w c')\n",
        "\n",
        "        # Ewentualne przetwarzanie za pomocą transformacji\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "    def next_chunk(self):\n",
        "        \"\"\"Funkcja ładuje następny segment i zwraca, czy zostały jeszcze segmenty.\"\"\"\n",
        "        self.chunk_idx += 1\n",
        "        if self.chunk_idx < self.num_chunks:\n",
        "            self._load_chunk(self.chunk_idx)\n",
        "            return True  # Oznacza, że załadowano nowy segment i można kontynuować\n",
        "        else:\n",
        "            self.chunk_idx = 0  # Resetujemy indeks na koniec epok\n",
        "            return False  # Oznacza, że skończyliśmy wszystkie segmenty\n",
        "'''"
      ],
      "metadata": {
        "id": "VfVX9XyW5yw_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "dd69140f-9393-44ff-f2f8-d92a6d952065"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass HDF5Dataset(Dataset):\\n    def __init__(self, file_path, transform=None, chunk_size=1000, n_samples=None):\\n        self.file_path = file_path\\n        self.transform = transform\\n        self.chunk_size = chunk_size\\n        self.n_samples = n_samples\\n\\n        # Ustalamy całkowitą liczbę próbek\\n        with h5py.File(self.file_path, \\'r\\') as h5_file:\\n            self.total_samples = min(len(h5_file[\\'image\\']), self.n_samples) if self.n_samples else len(h5_file[\\'image\\'])\\n\\n        self.current_chunk = None  # Zmienna przechowująca bieżący segment\\n        self.num_chunks = (self.total_samples + self.chunk_size - 1) // self.chunk_size  # Liczba segmentów\\n        self.chunk_idx = 0  # Indeks bieżącego segmentu\\n\\n        # Ładujemy pierwszy segment danych\\n        self._load_chunk(0)\\n\\n    def _load_chunk(self, chunk_idx):\\n        \"\"\"Ładuje segment danych bazując na indeksie segmentu.\"\"\"\\n        #start_time = time.time()\\n\\n        start_idx = chunk_idx * self.chunk_size\\n        end_idx = min(start_idx + self.chunk_size, self.total_samples)\\n\\n        with h5py.File(self.file_path, \\'r\\') as h5_file:\\n            self.current_chunk = h5_file[\\'image\\'][start_idx:end_idx]\\n\\n        self.current_chunk_start = start_idx\\n        #load_time = time.time() - start_time\\n        #print(f\"Loaded chunk {chunk_idx + 1}/{self.num_chunks} from {start_idx} to {end_idx} in {load_time:.4f} seconds\")\\n\\n    def __len__(self):\\n        return len(self.current_chunk)\\n\\n    def __getitem__(self, idx):\\n        # Pobieranie obrazu z aktualnie załadowanego segmentu\\n        image = self.current_chunk[idx]\\n\\n        # Ewentualne przekształcenie wymiarów\\n        if image.shape[0] == 3:\\n            image = rearrange(image, \\'c h w -> h w c\\')\\n\\n        # Ewentualne przetwarzanie za pomocą transformacji\\n        if self.transform:\\n            image = self.transform(image)\\n\\n        return image\\n\\n    def next_chunk(self):\\n        \"\"\"Funkcja ładuje następny segment i zwraca, czy zostały jeszcze segmenty.\"\"\"\\n        self.chunk_idx += 1\\n        if self.chunk_idx < self.num_chunks:\\n            self._load_chunk(self.chunk_idx)\\n            return True  # Oznacza, że załadowano nowy segment i można kontynuować\\n        else:\\n            self.chunk_idx = 0  # Resetujemy indeks na koniec epok\\n            return False  # Oznacza, że skończyliśmy wszystkie segmenty\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Klasa zbioru danych"
      ],
      "metadata": {
        "id": "oRmikokuCyF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HDF5Dataset(Dataset):\n",
        "    def __init__(self, file_path, transform=None, n_samples=None):\n",
        "        \"\"\"\n",
        "        Dataset do ładowania danych z pliku HDF5 i ograniczania liczby próbek.\n",
        "\n",
        "        Args:\n",
        "            file_path (str): Ścieżka do pliku HDF5.\n",
        "            n_samples (int, optional): Liczba próbek, które chcemy wykorzystać.\n",
        "            transform (callable, optional): Transformacje, np. augmentacja, normalizacja.\n",
        "        \"\"\"\n",
        "        self.file_path = file_path\n",
        "        self.transform = transform\n",
        "        self.n_samples = n_samples\n",
        "\n",
        "        # Otwieramy plik HDF5 raz, w konstruktorze klasy\n",
        "        self.h5f = h5py.File(self.file_path, 'r')\n",
        "        self.images = self.h5f['image'][:self.n_samples]  # Załadowanie grupy 'image'\n",
        "        print(f\"Załadowany kształt danych: {self.images.shape}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Załadowanie konkretnej próbki (obrazu) na podstawie indeksu\n",
        "        image_data = self.images[idx]  # Załadowanie jednej próbki (obrazu)\n",
        "\n",
        "        # Sprawdzamy kształt obrazu (C, H, W), jeśli konieczne, dokonujemy przekształcenia\n",
        "        if image_data.shape[0] == 3:\n",
        "            # Dostosowanie rozmiarów (jeśli używasz RGB, zmieniamy układ wymiarów na (h, w, c))\n",
        "            image_data = rearrange(image_data, 'c h w -> h w c')  # Zmiana na (h, w, c)\n",
        "\n",
        "        # Jeśli transformacje są zadane, stosujemy je\n",
        "        if self.transform:\n",
        "            image_data = self.transform(image_data)\n",
        "\n",
        "        return image_data\n",
        "\n",
        "    def __del__(self):\n",
        "        # Zamykanie pliku HDF5, kiedy instancja obiektu jest niszczona\n",
        "        self.h5f.close()"
      ],
      "metadata": {
        "id": "j2mFFRAM2JSV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fnxHJ_r05_v-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Stworzenie instancji klasy FeatureExtractor i przeniesienie na środowisko wykonawcze (CPU lub GPU)\n",
        "feature_extractor = FeatureExtractor(model).to(device)\n",
        "\n",
        "#Stworzenie instancji klasy HDF5Dataset\n",
        "#dataset = HDF5Dataset(file_path= file_path, transform=transform, chunk_size=chunk_size, n_samples=n_samples)\n",
        "dataset = HDF5Dataset(file_path= file_path, transform=transform, n_samples=n_samples)\n",
        "\n",
        "#Stworzenie instancji klasy DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=n_workers)\n",
        "\n",
        "#Ustawienie modelu ekstraktora cech w tryb treningu\n",
        "feature_extractor.train()\n",
        "\n",
        "#Definicja optymalizatora dla n-douczanych warstw\n",
        "params_to_train = [param for param in feature_extractor.parameters() if param.requires_grad]\n",
        "optimizer = optim.Adam(params_to_train, lr=1e-4)"
      ],
      "metadata": {
        "id": "rC_X0Lc90pJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a83310a-80fa-4dee-b8e3-cd40c2a3cc2f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Załadowany kształt danych: (1000, 3, 256, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epochs):\n",
        "    epoch_loss = 0  # Zmienna do liczenia średniego lossu na epokę\n",
        "    with tqdm(dataloader, unit=\"batch\", desc=f\"Epoch {epoch+1}/{n_epochs}\") as tepoch:\n",
        "        for batch_idx, data in enumerate(tepoch):\n",
        "\n",
        "            # Przenosimy dane na odpowiednie urządzenie (CPU lub GPU)\n",
        "            #data = data.to(device)\n",
        "            '''Włączyć gdy działamy na cuda, w innym wypadku wyłączyć to oszczędzamy jedną operację'''\n",
        "\n",
        "            #Przekazujemy dane przez model (Feature Extractor)\n",
        "            outputs = feature_extractor(data)\n",
        "\n",
        "            # Możesz dodać obliczanie lossu, jeśli to jest wymagane\n",
        "            # loss = criterion(outputs, targets)\n",
        "\n",
        "            # Obliczanie średniego lossu na epokę (jeśli masz loss)\n",
        "            # epoch_loss += loss.item()\n",
        "\n",
        "            # Aktualizacja postępu na pasku\n",
        "            tepoch.set_postfix(loss=epoch_loss / (batch_idx + 1) if batch_idx > 0 else 0)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "OzqURrlEmKBj",
        "outputId": "6f9af7f1-4c94-4c5a-bdbf-140aff6fa4b0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2: 100%|██████████| 500/500 [05:31<00:00,  1.51batch/s, loss=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:   1%|          | 5/500 [00:03<05:00,  1.65batch/s, loss=0]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-a35c8949f8b1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;31m#Przekazujemy dane przez model (Feature Extractor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# Możesz dodać obliczanie lossu, jeśli to jest wymagane\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-1cb174facdf1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         return F.max_pool2d(\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Wyniki testów (bez cuda, bo nie było dostępu gdy testowałem finalnie)\n",
        "'''\n",
        "Test 1:\n",
        "  Parametry:\n",
        "  n_samples = 1000     batch_size = 32    n_workers = 0   n_epochs = 2\n",
        "\n",
        "  Wyniki:\n",
        "  Czas wykonania:      1 epoka ~ 6 min    1 batch ~ (10 , 15) sekund\n",
        "\n",
        "  Accuracy: (Start: -, End: -)            Loss: (Start: -, End: -)\n",
        "\n",
        "  Uwagi:\n",
        "  -\n",
        "'''\n",
        "\n",
        "'''\n",
        "Test 2:\n",
        "  Parametry:\n",
        "  n_samples = 1000     batch_size = 32    n_workers = 2   n_epochs = 2\n",
        "\n",
        "  Wyniki:\n",
        "  Czas wykonania:      1 epoka ~ 7 min    1 batch ~ (10 , 15) sekund\n",
        "\n",
        "  Accuracy: (Start: -, End: -)            Loss: (Start: -, End: -)\n",
        "\n",
        "  Uwagi:\n",
        "  W trakcie realizacji 2 epoki wystąpił błąd (RuntimeError: DataLoader worker (pid 48010) is killed by signal: Killed.)\n",
        "  Prawdopodobnie przyczyną nie była pamięć (bo monitorowałem i była dostępna), a problem z wieloprocesowością.\n",
        "  Chat sugerował by otwierać plik dopiero w __getitem__, jednak to nie rozwiązuje problemu, a wydłuża czas realizacji\n",
        "'''\n",
        "\n",
        "'''\n",
        "Test 3:\n",
        "  Parametry:\n",
        "  n_samples = 1000     batch_size = 2    n_workers = 0   n_epochs = 2\n",
        "\n",
        "  Wyniki:\n",
        "  Czas wykonania:      1 epoka ~ 5.5 min    1 batch ~ (1.2 , 1.7) sekund\n",
        "\n",
        "  Accuracy: (Start: -, End: -)            Loss: (Start: -, End: -)\n",
        "\n",
        "  Uwagi:\n",
        "  -\n",
        "'''"
      ],
      "metadata": {
        "id": "Cu6hNz_w5-P7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}